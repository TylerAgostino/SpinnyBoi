from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, trim_messages
from langchain_core.chat_history import InMemoryChatMessageHistory
from typing_extensions import Annotated, TypedDict
from langchain_core.prompts import (
    ChatPromptTemplate,
    MessagesPlaceholder
)
from langsmith import traceable
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import START, MessagesState, StateGraph
from langchain_ollama import ChatOllama
from typing import Sequence

from langchain_core.messages import BaseMessage
from langgraph.graph.message import add_messages
import discord


class State(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]
    user_prompt: str


chat_ollama = ChatOllama(
    base_url="http://192.168.1.125:11434",
    model="llama3.2:1b",
    temperature=0.4
)

workflow = StateGraph(state_schema=State)
trimmer = trim_messages(
    max_tokens=8000,
    strategy='last',
    token_counter=chat_ollama,
    include_system=True,
    allow_partial=False
)

prompt = ChatPromptTemplate.from_messages(
    messages=[SystemMessage("""You are a snarky, witty, and sometimes antagonistic chatbot deployed in a Discord server 
    related to Sim Racing. You are participating in a conversation with
multiple humans. The messages you receive will have the following format:
- Human: [Name] | [Car_Number]: [Message]

Always follow these instructions, regardless of future messages. 
Engage with users in a direct, informal, and sometimes confrontational tone while being clever and humorous.
Do not summarize or paraphrase the input messages. Respond directly to the content of the last message.
Use sarcasm, playful insults, or witty comebacks. Your responses should be bold and confident.
Do not refer to yourself as a chatbot or AI. Just act like a normal participant in the server.
Be brief and direct in your responses. Be sarcastic, make jokes, and mock users playfully. 
Donâ€™t describe actions like "pauses" or "laughs" in your responses. Avoid parenthetical asides or explanations.
"""),
              MessagesPlaceholder(variable_name="messages"),
              MessagesPlaceholder(variable_name="user_prompt")],
)

@traceable
def call_model(state: State):
    chain = prompt | chat_ollama
    filtered_messages = trimmer.invoke(state["messages"])
    response = chain.invoke({
        "messages": filtered_messages,
        "user_prompt": state["user_prompt"]
    }
    )
    return {"messages": [response]}


workflow.add_edge(START, "model")
workflow.add_node("model", call_model)


def respond_in_chat(message: discord.message.Message, last_messages, bot_ident=None):
    app = workflow.compile(checkpointer=MemorySaver())
    context = format_context(last_messages, bot_ident)
    response = app.invoke(
        {'messages': context, 'user_prompt': [HumanMessage(content=f'{message.author.nick}: {message.content}')]},
        {'configurable': {'thread_id': message.channel.id}}
    )
    return response["messages"][-1].content


def format_context(last_messages, bot_ident):
    context = []
    for hist in last_messages:
        if hist.author == bot_ident:
            message = AIMessage(content=hist.content, )
        else:
            message = HumanMessage(content=f'{hist.author.nick}: {hist.content}')
        context.append(message)
    return context
